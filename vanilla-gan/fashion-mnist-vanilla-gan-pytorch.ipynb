{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fashion-mnist-vanilla-gan-pytorch.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1a8QBd9YvhyfIC0CnSzzIKO1Es9zLmIZG","authorship_tag":"ABX9TyN8dLwP6tHc1yILZTux9Fa/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"T428LzjgVT5v","colab_type":"code","outputId":"b114bdf6-d8e8-4b72-bdca-501fa85a494e","executionInfo":{"status":"ok","timestamp":1585423290766,"user_tz":-180,"elapsed":6861,"user":{"displayName":"Alexandr Yusov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIB0Jyn_zylDGc7YA-SNP1sopqaNjZxlzSFawX=s64","userId":"05421886016420156254"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["!pip install torchvision"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.2)\n","Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.4.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X6K2QMKgm2tj","colab_type":"code","colab":{}},"source":["from torchvision.datasets import FashionMNIST\n","from torchvision import transforms\n","\n","import torch\n","from torch.utils.data import DataLoader\n","from torch import nn\n","from torch import optim\n","\n","from matplotlib import pyplot as plt\n","import numpy as np\n","\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TCok7DWK47_4","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p6ibtxU_VtCV","colab_type":"code","colab":{}},"source":["transformations = transforms.Compose([transforms.ToTensor(), \n","                                      transforms.Normalize(mean=[0.5, ], std=[0.5, ])])\n","\n","train_dataset = FashionMNIST('./train', download=True, transform=transformations)\n","test_dataset = FashionMNIST('./test', train=False, download=True, transform=transformations)\n","\n","# configs\n","batch_size = 16\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_dataloader = DataLoader(test_dataset)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TWtxuaAl0rLj","colab_type":"code","colab":{}},"source":["class Discriminator(nn.Module):\n","    def __init__(self, input_size: int, num_classes: int):\n","        super().__init__()\n","        self.input_size = input_size\n","        self.num_classes = num_classes\n","\n","        self.pack1 = nn.Sequential(\n","            nn.Linear(input_size, 512),\n","            nn.BatchNorm1d(512),\n","            nn.LeakyReLU(0.05)\n","        )\n","        self.pack2 = nn.Sequential(\n","            nn.Linear(512, 256),\n","            nn.BatchNorm1d(256),\n","            nn.LeakyReLU(0.05)\n","        )\n","        self.pack3 = nn.Sequential(\n","            nn.Linear(256, 128),\n","            nn.BatchNorm1d(128),\n","            nn.LeakyReLU(0.05)\n","        )\n","        self.pack4 = nn.Sequential(\n","            nn.Linear(128, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = x.view(-1, self.input_size)\n","        output = self.pack1(x)\n","        output = self.pack2(output)\n","        output = self.pack3(output)\n","        return self.pack4(output)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q5MYOV2F79Q_","colab_type":"code","colab":{}},"source":["class Generator(nn.Module):\n","    def __init__(self, noise_size: int, output_width: int):\n","        super().__init__()\n","        self.noise_size = noise_size\n","        self.output_width = output_width\n","\n","        self.linear1 = nn.Linear(noise_size, 128)\n","        self.batch_norm1 = nn.BatchNorm1d(128)\n","        self.linear2 = nn.Linear(128, 256)\n","        self.batch_norm2 = nn.BatchNorm1d(256)\n","        self.linear3 = nn.Linear(256, 512)\n","        self.batch_norm3 = nn.BatchNorm1d(512)\n","        self.linear4 = nn.Linear(512, output_width ** 2)\n","        self.activation = nn.ReLU()\n","\n","    def forward(self, x):\n","        out = self.activation(self.batch_norm1(self.linear1(x)))\n","        out = self.activation(self.batch_norm2(self.linear2(out)))\n","        out = self.activation(self.batch_norm3(self.linear3(out)))\n","        out = self.linear4(out).view(-1, 1, self.output_width, self.output_width)\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SeXKrpmTGZaA","colab_type":"code","colab":{}},"source":["class NoiseGenerator:\n","    def __init__(self, noise_dim: int, device):\n","        self.noise_dim: int = noise_dim\n","        self.device = device\n","\n","    def generate(self, batch_size: int):\n","        return torch.randn((batch_size, self.noise_dim)).to(self.device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2XYBC0SE_hWh","colab_type":"code","colab":{}},"source":["def init_nets(image_width: int, \n","              noise_dim: int,\n","              device):\n","    discriminator = Discriminator(image_width ** 2, 1).to(device)\n","    generator = Generator(noise_dim, image_width).to(device)\n","    return discriminator, generator\n","\n","noise_dim = 100\n","image_width = 28\n","num_classes = len(train_dataset.classes)\n","\n","# Models\n","D, G = init_nets(image_width, noise_dim, device)\n","noise_generator = NoiseGenerator(noise_dim, device)\n","\n","# Optimizers\n","D_opt = optim.RMSprop(D.parameters(), lr = 1e-3)\n","G_opt = optim.RMSprop(G.parameters(), lr = 1e-3)\n","\n","# Losses\n","criterion = nn.BCEWithLogitsLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KJYHV4bjRuuv","colab_type":"code","colab":{}},"source":["def get_sample_image(generator: nn.Module, \n","                     n_images: int, \n","                     noise_generator: NoiseGenerator):\n","    noise = noise_generator.generate(n_images)\n","    fake_images = np.squeeze(generator(noise).cpu().detach().numpy(), axis=1)\n","    output_img = np.zeros((28, n_images*28))\n","\n","    for i in range(n_images):\n","        output_img[:, 28*i:28*(i+1)] = fake_images[i]\n","\n","    return output_img"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j7hukkd9EGxb","colab_type":"code","outputId":"6baca3a6-f0c9-460a-df52-663b055c7e84","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# labels\n","true_labels = torch.ones(batch_size, 1).to(device)\n","fake_labels = torch.zeros(batch_size, 1).to(device)\n","\n","epochs = 25\n","n_critic = 1\n","\n","d_losses = []\n","g_losses = []\n","\n","for epoch in range(epochs):\n","    for step, (images, labels) in enumerate(train_dataloader):\n","        noise = noise_generator.generate(batch_size)\n","        fake_images = G(noise)\n","        predicted_fake_labels = D(fake_images)\n","        fake_loss = criterion(predicted_fake_labels, fake_labels)\n","\n","        images = images.to(device)\n","        predicted_true_labels = D(images)\n","        true_loss = criterion(predicted_true_labels, true_labels)\n","\n","        discriminator_loss = fake_loss + true_loss\n","        D.zero_grad()\n","        discriminator_loss.backward()\n","        D_opt.step()\n","\n","        if step % n_critic == 0:\n","            noise = noise_generator.generate(batch_size)\n","            predicted_fake_labels = D(G(noise))\n","            G_loss = criterion(predicted_fake_labels, true_labels)\n","\n","            G.zero_grad()\n","            G_loss.backward()\n","            G_opt.step()\n","\n","        if step % 200 == 0:\n","            d_losses.append(discriminator_loss.item())\n","            g_losses.append(G_loss.item())\n","\n","        if step % 499 == 0:\n","            print('Epoch: {}/{}, Step: {}, D Loss: {}, G Loss: {}'.format(epoch, epochs, step, discriminator_loss.item(), G_loss.item()))\n","            \n","            G.eval()\n","            img = get_sample_image(G, 8, noise_generator)\n","\n","            dirname = 'samples'\n","            if not os.path.exists(dirname): os.makedirs(dirname)\n","            plt.imsave('{}/{}_{}_{}.jpg'.format(dirname, \"Vanilla-GAN\", str(epoch).zfill(2), str(step).zfill(4)), img, cmap='gray')\n","\n","            G.train()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 0/25, Step: 0, D Loss: 1.4579217433929443, G Loss: 0.7650353908538818\n","Epoch: 0/25, Step: 499, D Loss: 0.8551731109619141, G Loss: 1.15485680103302\n","Epoch: 0/25, Step: 998, D Loss: 1.4883277416229248, G Loss: 1.6045719385147095\n","Epoch: 0/25, Step: 1497, D Loss: 0.9425194263458252, G Loss: 3.7760517597198486\n","Epoch: 0/25, Step: 1996, D Loss: 0.08200238645076752, G Loss: 4.819361686706543\n","Epoch: 0/25, Step: 2495, D Loss: 0.12142277508974075, G Loss: 3.295644760131836\n","Epoch: 0/25, Step: 2994, D Loss: 0.5682553052902222, G Loss: 3.8770785331726074\n","Epoch: 0/25, Step: 3493, D Loss: 0.23580729961395264, G Loss: 1.5679724216461182\n","Epoch: 1/25, Step: 0, D Loss: 0.47671765089035034, G Loss: 4.796777248382568\n","Epoch: 1/25, Step: 499, D Loss: 1.0586532354354858, G Loss: 4.165494918823242\n","Epoch: 1/25, Step: 998, D Loss: 0.05622059106826782, G Loss: 3.729593515396118\n","Epoch: 1/25, Step: 1497, D Loss: 0.051049187779426575, G Loss: 4.0515007972717285\n","Epoch: 1/25, Step: 1996, D Loss: 0.13238558173179626, G Loss: 3.5283913612365723\n","Epoch: 1/25, Step: 2495, D Loss: 0.025639120489358902, G Loss: 2.7726778984069824\n","Epoch: 1/25, Step: 2994, D Loss: 0.11409898847341537, G Loss: 1.7218029499053955\n","Epoch: 1/25, Step: 3493, D Loss: 0.30550944805145264, G Loss: 4.527828216552734\n","Epoch: 2/25, Step: 0, D Loss: 0.07872608304023743, G Loss: 3.5405802726745605\n","Epoch: 2/25, Step: 499, D Loss: 0.024482086300849915, G Loss: 5.819442272186279\n","Epoch: 2/25, Step: 998, D Loss: 0.19386233389377594, G Loss: 3.684312343597412\n","Epoch: 2/25, Step: 1497, D Loss: 0.49082934856414795, G Loss: 5.034517288208008\n","Epoch: 2/25, Step: 1996, D Loss: 0.029592592269182205, G Loss: 4.600025177001953\n","Epoch: 2/25, Step: 2495, D Loss: 0.06262610107660294, G Loss: 3.1886796951293945\n","Epoch: 2/25, Step: 2994, D Loss: 0.08948634564876556, G Loss: 1.8459445238113403\n","Epoch: 2/25, Step: 3493, D Loss: 0.1300908625125885, G Loss: 5.564314365386963\n","Epoch: 3/25, Step: 0, D Loss: 0.17049385607242584, G Loss: 3.495206117630005\n","Epoch: 3/25, Step: 499, D Loss: 2.1792147159576416, G Loss: 1.2696125507354736\n","Epoch: 3/25, Step: 998, D Loss: 0.26528745889663696, G Loss: 3.5129942893981934\n","Epoch: 3/25, Step: 1497, D Loss: 0.40835607051849365, G Loss: 3.408539295196533\n","Epoch: 3/25, Step: 1996, D Loss: 0.11229320615530014, G Loss: 6.2938995361328125\n","Epoch: 3/25, Step: 2495, D Loss: 0.06754623353481293, G Loss: 5.421468257904053\n","Epoch: 3/25, Step: 2994, D Loss: 0.03496582806110382, G Loss: 4.484155654907227\n","Epoch: 3/25, Step: 3493, D Loss: 0.22593970596790314, G Loss: 4.264553546905518\n","Epoch: 4/25, Step: 0, D Loss: 0.27113422751426697, G Loss: 6.347879409790039\n","Epoch: 4/25, Step: 499, D Loss: 0.04926601052284241, G Loss: 6.322901248931885\n","Epoch: 4/25, Step: 998, D Loss: 0.01785634085536003, G Loss: 6.1958112716674805\n","Epoch: 4/25, Step: 1497, D Loss: 0.36330607533454895, G Loss: 2.385249614715576\n","Epoch: 4/25, Step: 1996, D Loss: 0.2848913073539734, G Loss: 4.59047794342041\n","Epoch: 4/25, Step: 2495, D Loss: 0.6584179997444153, G Loss: 2.837947130203247\n","Epoch: 4/25, Step: 2994, D Loss: 0.08977361768484116, G Loss: 5.1846208572387695\n","Epoch: 4/25, Step: 3493, D Loss: 0.009150560013949871, G Loss: 5.267428398132324\n","Epoch: 5/25, Step: 0, D Loss: 0.15915779769420624, G Loss: 5.548554420471191\n","Epoch: 5/25, Step: 499, D Loss: 0.08734452724456787, G Loss: 4.35004997253418\n","Epoch: 5/25, Step: 998, D Loss: 0.12699873745441437, G Loss: 4.202182769775391\n","Epoch: 5/25, Step: 1497, D Loss: 0.0832652598619461, G Loss: 6.661263942718506\n","Epoch: 5/25, Step: 1996, D Loss: 0.5742054581642151, G Loss: 8.467620849609375\n","Epoch: 5/25, Step: 2495, D Loss: 0.007646451238542795, G Loss: 7.105713367462158\n","Epoch: 5/25, Step: 2994, D Loss: 1.4024677276611328, G Loss: 4.366736888885498\n","Epoch: 5/25, Step: 3493, D Loss: 0.8826769590377808, G Loss: 6.210917949676514\n","Epoch: 6/25, Step: 0, D Loss: 0.4537099301815033, G Loss: 6.358414649963379\n","Epoch: 6/25, Step: 499, D Loss: 0.1977529376745224, G Loss: 4.812487602233887\n","Epoch: 6/25, Step: 998, D Loss: 0.14408425986766815, G Loss: 6.348653793334961\n","Epoch: 6/25, Step: 1497, D Loss: 0.04709872603416443, G Loss: 3.5317134857177734\n","Epoch: 6/25, Step: 1996, D Loss: 0.028919026255607605, G Loss: 5.638258934020996\n","Epoch: 6/25, Step: 2495, D Loss: 0.043520815670490265, G Loss: 3.95481014251709\n","Epoch: 6/25, Step: 2994, D Loss: 0.01635570637881756, G Loss: 2.6865170001983643\n","Epoch: 6/25, Step: 3493, D Loss: 0.027673952281475067, G Loss: 4.587053298950195\n","Epoch: 7/25, Step: 0, D Loss: 0.10666391253471375, G Loss: 8.062359809875488\n","Epoch: 7/25, Step: 499, D Loss: 0.014293752610683441, G Loss: 2.7006804943084717\n","Epoch: 7/25, Step: 998, D Loss: 0.6905797719955444, G Loss: 3.205700397491455\n","Epoch: 7/25, Step: 1497, D Loss: 0.017035719007253647, G Loss: 4.949029922485352\n","Epoch: 7/25, Step: 1996, D Loss: 0.25122037529945374, G Loss: 7.453281402587891\n","Epoch: 7/25, Step: 2495, D Loss: 0.5777883529663086, G Loss: 2.320786476135254\n","Epoch: 7/25, Step: 2994, D Loss: 0.07976654171943665, G Loss: 4.398419380187988\n","Epoch: 7/25, Step: 3493, D Loss: 0.04296770319342613, G Loss: 0.9194304943084717\n","Epoch: 8/25, Step: 0, D Loss: 0.5637519955635071, G Loss: 6.68428373336792\n","Epoch: 8/25, Step: 499, D Loss: 0.017677880823612213, G Loss: 6.160064697265625\n","Epoch: 8/25, Step: 998, D Loss: 0.2682851552963257, G Loss: 5.61796236038208\n","Epoch: 8/25, Step: 1497, D Loss: 0.0380057618021965, G Loss: 3.1947455406188965\n","Epoch: 8/25, Step: 1996, D Loss: 0.020676670596003532, G Loss: 3.813868522644043\n","Epoch: 8/25, Step: 2495, D Loss: 0.079434335231781, G Loss: 5.193012714385986\n","Epoch: 8/25, Step: 2994, D Loss: 0.11491710692644119, G Loss: 7.331122875213623\n","Epoch: 8/25, Step: 3493, D Loss: 0.014373061247169971, G Loss: 4.255061149597168\n","Epoch: 9/25, Step: 0, D Loss: 0.008156931027770042, G Loss: 5.577365875244141\n","Epoch: 9/25, Step: 499, D Loss: 0.0951937735080719, G Loss: 3.5845398902893066\n","Epoch: 9/25, Step: 998, D Loss: 0.0276169516146183, G Loss: 8.179814338684082\n","Epoch: 9/25, Step: 1497, D Loss: 0.41461536288261414, G Loss: 7.775073051452637\n","Epoch: 9/25, Step: 1996, D Loss: 0.1541101187467575, G Loss: 5.7214460372924805\n","Epoch: 9/25, Step: 2495, D Loss: 0.1167052760720253, G Loss: 1.4805060625076294\n","Epoch: 9/25, Step: 2994, D Loss: 0.7416732311248779, G Loss: 6.044778823852539\n","Epoch: 9/25, Step: 3493, D Loss: 0.002736660884693265, G Loss: 8.450185775756836\n","Epoch: 10/25, Step: 0, D Loss: 0.02893897518515587, G Loss: 5.794936180114746\n","Epoch: 10/25, Step: 499, D Loss: 0.38258954882621765, G Loss: 2.682063102722168\n","Epoch: 10/25, Step: 998, D Loss: 0.07847185432910919, G Loss: 5.169107437133789\n","Epoch: 10/25, Step: 1497, D Loss: 0.014634428545832634, G Loss: 4.596527099609375\n","Epoch: 10/25, Step: 1996, D Loss: 0.6079137921333313, G Loss: 5.005199909210205\n","Epoch: 10/25, Step: 2495, D Loss: 0.05869995802640915, G Loss: 4.018659591674805\n","Epoch: 10/25, Step: 2994, D Loss: 0.12016960978507996, G Loss: 5.490598678588867\n","Epoch: 10/25, Step: 3493, D Loss: 0.006059947889298201, G Loss: 6.558483600616455\n","Epoch: 11/25, Step: 0, D Loss: 0.12180105596780777, G Loss: 3.5060102939605713\n","Epoch: 11/25, Step: 499, D Loss: 0.00493680639192462, G Loss: 3.058454751968384\n","Epoch: 11/25, Step: 998, D Loss: 0.003010593121871352, G Loss: 5.325107574462891\n","Epoch: 11/25, Step: 1497, D Loss: 0.003072199411690235, G Loss: 6.978199005126953\n","Epoch: 11/25, Step: 1996, D Loss: 0.13034595549106598, G Loss: 5.201329708099365\n","Epoch: 11/25, Step: 2495, D Loss: 0.06326031684875488, G Loss: 7.847904205322266\n","Epoch: 11/25, Step: 2994, D Loss: 0.005999690853059292, G Loss: 6.834738254547119\n","Epoch: 11/25, Step: 3493, D Loss: 0.05188079923391342, G Loss: 1.5937343835830688\n","Epoch: 12/25, Step: 0, D Loss: 0.012866845354437828, G Loss: 3.6251089572906494\n","Epoch: 12/25, Step: 499, D Loss: 0.3220994472503662, G Loss: 7.169939041137695\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U6bHezg-aCMR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}